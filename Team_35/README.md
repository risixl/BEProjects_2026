DeepISL
A Machine Learning Approach for Bidirectional Translation Between Indian Sign Language and Text

ğŸ“Œ Project Overview

DeepISL is a real-time, web-based system designed to enable bidirectional communication between the hearing and hearing-impaired communities. The system translates Indian Sign Language (ISL) gestures to English text and also converts English text into animated ISL representations.

Unlike traditional systems that focus only on isolated gesture recognition, DeepISL integrates gesture recognition, linguistic processing, and sign animation generation into a single unified framework. The project emphasizes accuracy, low latency, and deployability on CPU-based systems, making it suitable for real-world accessibility applications.

ğŸ¯ Objectives

To recognize dynamic ISL gestures in real time using skeletal keypoints

To design a hybrid CNNâ€“Transformer architecture for robust temporal modeling

To convert recognized ISL gestures into grammatically correct English sentences

To support reverse translation (Text â†’ ISL) using gloss mapping and animation synthesis

To build a scalable and user-friendly system for inclusive communication

ğŸš€ How to Run the Project

Clone the repository

Install dependencies:

pip install -r requirements.txt

Run the Flask server:

python app.py

Open the application in a browser and allow webcam access

ğŸ‘©â€ğŸ’» Team Members

R. Moushmi Srimayi (1CR22CS140)

K. Umme Habeeba (1CR22CS077)

Monika S V (1CR22CS108)
